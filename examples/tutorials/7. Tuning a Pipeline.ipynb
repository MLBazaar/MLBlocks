{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning a Pipeline\n",
    "\n",
    "This short guide shows how tune a Pipeline using a [BTB](https://github.com/HDI-Project/BTB) Tuner.\n",
    "\n",
    "Note that some steps are not explained for simplicity. Full details\n",
    "about them can be found in the previous parts of the tutorial.\n",
    "\n",
    "Here we will:\n",
    "1. Load a dataset and a pipeline\n",
    "2. Explore the pipeline tunable hyperparameters\n",
    "3. Write a scoring function\n",
    "4. Build a BTB Tunable and BTB Tuner.\n",
    "5. Write a tuning loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and the pipeline\n",
    "\n",
    "The first step will be to load the dataset that we were using in previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlprimitives.datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('census')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load a suitable pipeline.\n",
    "\n",
    "Note how in this case we are using the variable name `template` instead of `pipeline`,\n",
    "because this will only be used as a template for the pipelines that we will create\n",
    "and evaluate during the later tuning loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlblocks import MLPipeline\n",
    "\n",
    "template = MLPipeline('single_table.classification.xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the pipeline tunable hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have loaded the pipeline, we can now extract the hyperparameters that we will tune\n",
    "by calling the `get_tunable_hyperparameters` method.\n",
    "\n",
    "In this case we will call it using `flat=True` to obtain the hyperparameters in a format\n",
    "that is compatible with BTB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunable_hyperparameters = template.get_tunable_hyperparameters(flat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "  'max_labels'): {'type': 'int', 'default': 0, 'range': [0, 100]},\n",
       " ('sklearn.impute.SimpleImputer#1', 'strategy'): {'type': 'str',\n",
       "  'default': 'mean',\n",
       "  'values': ['mean', 'median', 'most_frequent', 'constant']},\n",
       " ('xgboost.XGBClassifier#1', 'n_estimators'): {'type': 'int',\n",
       "  'default': 100,\n",
       "  'range': [10, 1000]},\n",
       " ('xgboost.XGBClassifier#1', 'max_depth'): {'type': 'int',\n",
       "  'default': 3,\n",
       "  'range': [3, 10]},\n",
       " ('xgboost.XGBClassifier#1', 'learning_rate'): {'type': 'float',\n",
       "  'default': 0.1,\n",
       "  'range': [0, 1]},\n",
       " ('xgboost.XGBClassifier#1', 'gamma'): {'type': 'float',\n",
       "  'default': 0,\n",
       "  'range': [0, 1]},\n",
       " ('xgboost.XGBClassifier#1', 'min_child_weight'): {'type': 'int',\n",
       "  'default': 1,\n",
       "  'range': [1, 10]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunable_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a scoring function\n",
    "\n",
    "To tune the pipeline we will need to evaluate its performance multiple times with different hyperparameters.\n",
    "\n",
    "For this reason, we will start by writing a scoring function that will expect only one\n",
    "input, the hyperparameters dictionary, and evaluate the performance of the pipeline using them.\n",
    "\n",
    "In this case, the evaluation will be done using 5-fold cross validation based on the `get_splits`\n",
    "method from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_validate(hyperparameters=None):\n",
    "    scores = []\n",
    "    for X_train, X_test, y_train, y_test in dataset.get_splits(5):\n",
    "        pipeline = MLPipeline(template.to_dict())  # Make a copy of the template\n",
    "        if hyperparameters:\n",
    "            pipeline.set_hyperparameters(hyperparameters)\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        scores.append(dataset.score(y_test, y_pred))\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling this function without any arguments we will obtain the score obtained\n",
    "with the default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8639171383183359"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_score = cross_validate()\n",
    "default_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can certify that by passing a hyperparameters dictionary the new hyperparameters\n",
    "will be used, resulting on a different score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686773872402614"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    ('xgboost.XGBClassifier#1', 'max_depth'): 4\n",
    "}\n",
    "cross_validate(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a BTB Tunable\n",
    "\n",
    "The next step is to create the BTB Tunable instance that will be tuned by the BTB Tuner.\n",
    "\n",
    "For this we will use its `from_dict` method, passing our hyperparameters dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning import Tunable\n",
    "\n",
    "tunable = Tunable.from_dict(tunable_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the BTB Tuner\n",
    "\n",
    "After creating the Tunable, we need to create a Tuner to tune it.\n",
    "\n",
    "In this case we will use the GPTuner, a Meta-model based tuner that uses a Gaussian Process Regressor\n",
    "for the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning import GPTuner\n",
    "\n",
    "tuner = GPTuner(tunable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, since we already know the score obtained by the default arguments and\n",
    "these have a high probability of being already decent, we will inform the tuner\n",
    "about their performance.\n",
    "\n",
    "In order to obtain the default hyperparameters used before we can either call\n",
    "the template `get_hyperparameters(flat=True)` method, the `tunable.get_defaults()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "  'max_labels'): 0,\n",
       " ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       " ('xgboost.XGBClassifier#1', 'n_estimators'): 100,\n",
       " ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       " ('xgboost.XGBClassifier#1', 'learning_rate'): 0.1,\n",
       " ('xgboost.XGBClassifier#1', 'gamma'): 0.0,\n",
       " ('xgboost.XGBClassifier#1', 'min_child_weight'): 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaults = tunable.get_defaults()\n",
    "defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.record(defaults, default_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Tuning loop\n",
    "\n",
    "Once we have the tuner ready we can the tuning loop.\n",
    "\n",
    "During this loop we will:\n",
    "\n",
    "1. Ask the tuner for a new hyperparameter proposal\n",
    "2. Run the `cross_validate` function to evaluate these hyperparameters\n",
    "3. Record the obtained score back to the tuner.\n",
    "4. If the obtained score is better than the previous one, store the proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring pipeline 1\n",
      "scoring pipeline 2\n",
      "scoring pipeline 3\n",
      "scoring pipeline 4\n",
      "New best found: 0.8642241881762839\n",
      "scoring pipeline 5\n",
      "scoring pipeline 6\n",
      "scoring pipeline 7\n",
      "New best found: 0.8644390957265209\n",
      "scoring pipeline 8\n",
      "New best found: 0.8679095503945804\n",
      "scoring pipeline 9\n",
      "scoring pipeline 10\n"
     ]
    }
   ],
   "source": [
    "best_score = default_score\n",
    "best_proposal = defaults\n",
    "\n",
    "for iteration in range(10):\n",
    "    print(\"scoring pipeline {}\".format(iteration + 1))\n",
    "    \n",
    "    proposal = tuner.propose()\n",
    "    score = cross_validate(proposal)\n",
    "    \n",
    "    tuner.record(proposal, score)\n",
    "    \n",
    "    if score > best_score:\n",
    "        print(\"New best found: {}\".format(score))\n",
    "        best_score = score\n",
    "        best_proposal = proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the loop has finished, the best proposal will be stored in the `best_proposal` variable,\n",
    "which can be used to generate a new pipeline instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "  'max_labels'): 39,\n",
       " ('sklearn.impute.SimpleImputer#1', 'strategy'): 'most_frequent',\n",
       " ('xgboost.XGBClassifier#1', 'n_estimators'): 70,\n",
       " ('xgboost.XGBClassifier#1', 'max_depth'): 6,\n",
       " ('xgboost.XGBClassifier#1', 'learning_rate'): 0.07406443671152008,\n",
       " ('xgboost.XGBClassifier#1', 'gamma'): 0.9244108160038952,\n",
       " ('xgboost.XGBClassifier#1', 'min_child_weight'): 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = MLPipeline(template.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline.set_hyperparameters(best_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline.fit(dataset.data, dataset.target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting and Tuning pipelines\n",
    "\n",
    "This guide shows you how to search for multiple pipelines for your problem\n",
    "and later on use a [BTBSession](https://mlbazaar.github.io/BTB/api/btb.session.html#btb.session.BTBSession)\n",
    "to select and tune the best one.\n",
    "\n",
    "Note that some steps are not explained for simplicity. Full details\n",
    "about them can be found in the previous parts of the tutorial.\n",
    "\n",
    "Here we will:\n",
    "\n",
    "1. Load a dataset\n",
    "2. Search and load suitable templates\n",
    "3. Write a scoring function\n",
    "4. Build a BTBSession for our templates\n",
    "5. Run the session to find the best pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "The first step will be to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_census\n",
    "\n",
    "dataset = load_census()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult Census dataset.\n",
      "\n",
      "    Predict whether income exceeds $50K/yr based on census data. Also known as \"Adult\" dataset.\n",
      "\n",
      "    Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean\n",
      "    records was extracted using the following conditions: ((AAGE>16) && (AGI>100) &&\n",
      "    (AFNLWGT>1)&& (HRSWK>0))\n",
      "\n",
      "    Prediction task is to determine whether a person makes over 50K a year.\n",
      "\n",
      "    source: \"UCI\n",
      "    sourceURI: \"https://archive.ics.uci.edu/ml/datasets/census+income\"\n",
      "    \n",
      "Data Modality: single_table\n",
      "Task Type: classification\n",
      "Task Subtype: binary\n",
      "Data shape: (32561, 14)\n",
      "Target shape: (32561,)\n",
      "Metric: accuracy_score\n",
      "Extras: \n"
     ]
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and load suitable Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `mlblocks.discovery.find_pipelines` function to search\n",
    "for compatible pipelines.\n",
    "\n",
    "In this case, we will be looking for `single_table/classification` pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlblocks.discovery import find_pipelines\n",
    "\n",
    "templates = find_pipelines('single_table.classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['single_table.classification',\n",
       " 'single_table.classification.text',\n",
       " 'single_table.classification.xgb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will create a dictionary with MLPipeline instances that will be used as tempaltes for our tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlblocks import MLPipeline\n",
    "\n",
    "templates_dict = {\n",
    "    template: MLPipeline(template)\n",
    "    for template in templates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlblocks.mlpipeline.MLPipeline at 0x293518790>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates_dict['single_table.classification.xgb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a scoring function\n",
    "\n",
    "In order to use a `BTBSession` we will need a function that is able to score a proposal,\n",
    "which will always be a pair of template name and proposed hyperparameters.\n",
    "\n",
    "In this case, the evaluation will be done using 5-fold cross validation over our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_validate(template_name, hyperparameters=None):\n",
    "    template = templates_dict[template_name]\n",
    "    scores = []\n",
    "    for X_train, X_test, y_train, y_test in dataset.get_splits(5):\n",
    "        pipeline = MLPipeline(template.to_dict())  # Make a copy of the template\n",
    "        if hyperparameters:\n",
    "            pipeline.set_hyperparameters(hyperparameters)\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        scores.append(dataset.score(y_test, y_pred))\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the BTBSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create another dictionary with the tunable hyperparameters of each template.\n",
    "This will be used by the BTBSession to know how to tune each template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunables = {\n",
    "    name: template.get_tunable_hyperparameters(flat=True)\n",
    "    for name, template in templates_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "  'max_labels'): {'type': 'int', 'default': 0, 'range': [0, 100]},\n",
       " ('sklearn.impute.SimpleImputer#1', 'strategy'): {'type': 'str',\n",
       "  'default': 'mean',\n",
       "  'values': ['mean', 'median', 'most_frequent', 'constant']},\n",
       " ('xgboost.XGBClassifier#1', 'n_estimators'): {'type': 'int',\n",
       "  'default': 100,\n",
       "  'range': [10, 1000]},\n",
       " ('xgboost.XGBClassifier#1', 'max_depth'): {'type': 'int',\n",
       "  'default': 3,\n",
       "  'range': [3, 10]},\n",
       " ('xgboost.XGBClassifier#1', 'learning_rate'): {'type': 'float',\n",
       "  'default': 0.1,\n",
       "  'range': [0, 1]},\n",
       " ('xgboost.XGBClassifier#1', 'gamma'): {'type': 'float',\n",
       "  'default': 0,\n",
       "  'range': [0, 1]},\n",
       " ('xgboost.XGBClassifier#1', 'min_child_weight'): {'type': 'int',\n",
       "  'default': 1,\n",
       "  'range': [1, 10]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunables['single_table.classification.xgb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then create a `BTBSession` instance passing them and the `cross_validate` function.\n",
    "\n",
    "We will also be setting it in `verbose` mode, so we can have a better insight on what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baytune.session import BTBSession\n",
    "\n",
    "session = BTBSession(tunables, cross_validate, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After everything is set up, we can start running the tuning session passing it\n",
    "the number of iterations that we want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c20e4b982f42a1873c0d12f550ee4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception caught producing MLBlock mlprimitives.custom.text.TextCleaner#1\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3802, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'text'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarah/Documents/git-repos/MLBlocks/mlblocks/mlpipeline.py\", line 679, in _produce_block\n",
      "    block_outputs = block.produce(**produce_args)\n",
      "  File \"/Users/sarah/Documents/git-repos/MLBlocks/mlblocks/mlblock.py\", line 331, in produce\n",
      "    return getattr(self.instance, self.produce_method)(**produce_kwargs)\n",
      "  File \"/Users/sarah/Documents/git-repos/MLPrimitives/mlprimitives/custom/text.py\", line 111, in produce\n",
      "    texts = X[self.column]\n",
      "  File \"/opt/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/frame.py\", line 3807, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/opt/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3804, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'text'\n",
      "Proposal 2 - single_table.classification.text crashed with the following configuration: ('mlprimitives.custom.text.TextCleaner#1', 'lower'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'accents'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'stopwords'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'non_alpha'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'single_chars'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'lowercase'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'binary'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'max_features'): 1000\n",
      "('sklearn.impute.SimpleImputer#1', 'strategy'): mean\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'n_estimators'): 10\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'criterion'): gini\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'max_features'): None\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'max_depth'): 1\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_split'): 2\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_leaf'): 1\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_weight_fraction_leaf'): 0.0\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'max_leaf_nodes'): 2\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_impurity_decrease'): 0.0\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'bootstrap'): True\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'oob_score'): False\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3802, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'text'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py10/lib/python3.10/site-packages/baytune/session.py\", line 364, in run\n",
      "    score = self._scorer(tunable_name, config)\n",
      "  File \"/var/folders/by/d1f3gk0x14v54qggfxmjbn1c0000gn/T/ipykernel_19852/2674531477.py\", line 11, in cross_validate\n",
      "    pipeline.fit(X_train, y_train)\n",
      "  File \"/Users/sarah/Documents/git-repos/MLBlocks/mlblocks/mlpipeline.py\", line 805, in fit\n",
      "    self._produce_block(\n",
      "  File \"/Users/sarah/Documents/git-repos/MLBlocks/mlblocks/mlpipeline.py\", line 679, in _produce_block\n",
      "    block_outputs = block.produce(**produce_args)\n",
      "  File \"/Users/sarah/Documents/git-repos/MLBlocks/mlblocks/mlblock.py\", line 331, in produce\n",
      "    return getattr(self.instance, self.produce_method)(**produce_kwargs)\n",
      "  File \"/Users/sarah/Documents/git-repos/MLPrimitives/mlprimitives/custom/text.py\", line 111, in produce\n",
      "    texts = X[self.column]\n",
      "  File \"/opt/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/frame.py\", line 3807, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/opt/anaconda3/envs/py10/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3804, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'text'\n",
      "Too many errors: 1. Removing tunable single_table.classification.text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '0ebe8af9c06a05f39821de36d6c9ffc2',\n",
       " 'name': 'single_table.classification.xgb',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 52,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'median',\n",
       "  ('xgboost.XGBClassifier#1', 'n_estimators'): 313,\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 5,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.7119589664956909,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.944854007471167,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 10},\n",
       " 'score': 0.8641320270062784}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this loop, the BTBSession will build pipelines based on our templates and evaluate them\n",
    "using our scoring function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate results\n",
    "\n",
    "When the session funishes running it will return a the best proposal available and the\n",
    "obtained score.\n",
    "\n",
    "These results are also available as the `best_proposal` attribute from the btb session object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0ebe8af9c06a05f39821de36d6c9ffc2',\n",
       " 'name': 'single_table.classification.xgb',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 52,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'median',\n",
       "  ('xgboost.XGBClassifier#1', 'n_estimators'): 313,\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 5,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.7119589664956909,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.944854007471167,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 10},\n",
       " 'score': 0.8641320270062784}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.best_proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we feel that the score can still be improved and want to keep searching, we can simply run the session again which will continue tuning over the previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dbe69a0340455a937f7376f7723ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '0e379b2b0932f77d9b541925a05716be',\n",
       " 'name': 'single_table.classification.xgb',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 43,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'median',\n",
       "  ('xgboost.XGBClassifier#1', 'n_estimators'): 609,\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 5,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.16947366722929258,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.8805192101300107,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       " 'score': 0.8727005495718071}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If you look at the logs you will notice how the BTBSession captures the errors that finds\n",
    "while executing the pipelines and automatically discards the failing tempaltes to be able to continue\n",
    "the tuning session without wasting time on them.\n",
    "\n",
    "The number of errors that we want to wait before discarding a template can be changed passing the\n",
    "`max_errors` argument to the `BTBSession` when it is build.\n",
    "\n",
    "Isn't it cool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the best pipeline\n",
    "\n",
    "Once we are satisfied with the results, we can then build an instance of the best pipeline\n",
    "by reading the `best_proposal` attribute from the `session`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0e379b2b0932f77d9b541925a05716be',\n",
       " 'name': 'single_table.classification.xgb',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 43,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'median',\n",
       "  ('xgboost.XGBClassifier#1', 'n_estimators'): 609,\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 5,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.16947366722929258,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.8805192101300107,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       " 'score': 0.8727005495718071}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_proposal = session.best_proposal\n",
    "best_proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = templates_dict[best_proposal['name']]\n",
    "\n",
    "pipeline = MLPipeline(template.to_dict())\n",
    "pipeline.set_hyperparameters(best_proposal['config'])\n",
    "\n",
    "pipeline.fit(dataset.data, dataset.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore other results\n",
    "\n",
    "Optionally, if we are interested in exploring the results of the previous proposals we can access them\n",
    "in the `trials` attribute of the `session` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'c2cd14c7e9470448a0eeb58a3cce327f',\n",
       "  'name': 'single_table.classification',\n",
       "  'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "    'max_labels'): 0,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'lowercase'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'binary'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'max_features'): 1000,\n",
       "   ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "   ('xgboost.XGBClassifier#1', 'n_estimators'): 100,\n",
       "   ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "   ('xgboost.XGBClassifier#1', 'learning_rate'): 0.1,\n",
       "   ('xgboost.XGBClassifier#1', 'gamma'): 0.0,\n",
       "   ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       "  'score': 0.863978563379761},\n",
       " {'id': 'adbd189a819483ddc869ceb94513b369',\n",
       "  'name': 'single_table.classification.text',\n",
       "  'config': {('mlprimitives.custom.text.TextCleaner#1', 'lower'): True,\n",
       "   ('mlprimitives.custom.text.TextCleaner#1', 'accents'): True,\n",
       "   ('mlprimitives.custom.text.TextCleaner#1', 'stopwords'): True,\n",
       "   ('mlprimitives.custom.text.TextCleaner#1', 'non_alpha'): True,\n",
       "   ('mlprimitives.custom.text.TextCleaner#1', 'single_chars'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'lowercase'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'binary'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'max_features'): 1000,\n",
       "   ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'n_estimators'): 10,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'criterion'): 'gini',\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'max_features'): None,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'max_depth'): 1,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_split'): 2,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_leaf'): 1,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1',\n",
       "    'min_weight_fraction_leaf'): 0.0,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'max_leaf_nodes'): 2,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'min_impurity_decrease'): 0.0,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'bootstrap'): True,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'oob_score'): False},\n",
       "  'score': None}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(session.proposals.values())[0:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
